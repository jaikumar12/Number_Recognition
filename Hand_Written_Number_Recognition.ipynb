{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set random seed for reproducibility\n",
    "\n",
    "import numpy as np               # NumPy for numerical operations\n",
    "import matplotlib.pyplot as plt  # Matplotlib for plotting\n",
    "import seaborn as sns            # Seaborn for data visualization\n",
    "import cv2                       # OpenCV for image processing\n",
    "from PIL import Image            # Python Imaging Library for image handling\n",
    "import tensorflow as tf          # TensorFlow for deep learning\n",
    "tf.random.set_seed(3)            # Set a random seed for reproducible results\n",
    "from tensorflow import keras     # Keras, a high-level deep learning API\n",
    "from keras.datasets import mnist # MNIST dataset for digit classification\n",
    "from tensorflow.math import confusion_matrix  # TensorFlow math for confusion matrix\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48a6e8",
   "metadata": {},
   "source": [
    "Loading the MNIST data from keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e25d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset, which consists of handwritten digit images\n",
    "# The dataset is divided into two parts: training and testing data\n",
    "# (x_train, y_train): Training data, where x_train contains the images and y_train contains their corresponding labels\n",
    "# (x_test, y_test): Testing data, used to evaluate the model's performance\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4ef18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the data types of x_train\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784d7db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the datasets\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1941a",
   "metadata": {},
   "source": [
    "Training data = 60000 Images , Test data = 10000 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35d5e1",
   "metadata": {},
   "source": [
    "Image dimension --> 28 x 28\n",
    "Grayscale Image --> 1 Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaeed07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  42 118 219 166 118 118   6\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 103 242 254 254 254 254 254  66\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  18 232 254 254 254 254 254 238\n",
      "   70   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 104 244 254 224 254 254 254\n",
      "  141   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 207 254 210 254 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  84 206 254 254 254 254\n",
      "   41   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  24 209 254 254 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  91 137 253 254 254 254\n",
      "  112   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  40 214 250 254 254 254 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  81 247 254 254 254 254 254 254\n",
      "  146   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 110 246 254 254 254 254 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  73  89  89  93 240 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 128 254\n",
      "  219  31   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7 254 254\n",
      "  214  28   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 254\n",
      "  116   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  19 177  90   0   0   0   0   0  25 240 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 164 254 215  63  36   0  51  89 206 254 254 139\n",
      "    8   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  57 197 254 254 222 180 241 254 254 253 213  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 140 105 254 254 254 254 254 254 236   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 117 117 165 254 254 239  50   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the data of a specific image (in this case, the 10th image in the training set)\n",
    "\n",
    "print(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea599e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of a specific image\n",
    "print(x_train[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951dc347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Labels: 2\n"
     ]
    }
   ],
   "source": [
    "# Display an image (in this case, the 25th image in the training set)\n",
    "plt.imshow(x_train[25])\n",
    "plt.show()\n",
    "\n",
    "# Print the label corresponding to the displayed image\n",
    "print('Image Labels:', y_train[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30339277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and testing label sets\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c68e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique values in y_test: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Print unique values in y_train\n",
    "print('Unique values in y_train:', np.unique(y_train))\n",
    "\n",
    "# Print unique values in y_test\n",
    "print('Unique values in y_test:', np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e18c3a",
   "metadata": {},
   "source": [
    "we can these labels as such or we can also apply One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a468e",
   "metadata": {},
   "source": [
    "All the images have the same dimension in this datasets , if not , we have \n",
    "to resize all the Images to a common dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cb58191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the pixel values to a range between 0 and 1 (Normalization)\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a644226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Pixel Values of the 10th Image: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16470588\n",
      "  0.4627451  0.85882353 0.65098039 0.4627451  0.4627451  0.02352941\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.40392157 0.94901961\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.25882353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07058824 0.90980392\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.93333333\n",
      "  0.2745098  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40784314\n",
      "  0.95686275 0.99607843 0.87843137 0.99607843 0.99607843 0.99607843\n",
      "  0.55294118 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.81176471 0.99607843 0.82352941 0.99607843 0.99607843 0.99607843\n",
      "  0.13333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32941176 0.80784314 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.16078431 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09411765 0.81960784 0.99607843 0.99607843 0.99607843\n",
      "  0.67058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35686275 0.5372549  0.99215686 0.99607843 0.99607843 0.99607843\n",
      "  0.43921569 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.15686275 0.83921569\n",
      "  0.98039216 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.13333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.31764706 0.96862745\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.57254902 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.43137255\n",
      "  0.96470588 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.67058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.28627451 0.34901961 0.34901961 0.36470588 0.94117647 0.99607843\n",
      "  0.67058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.50196078 0.99607843\n",
      "  0.85882353 0.12156863 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02745098 0.99607843 0.99607843\n",
      "  0.83921569 0.10980392 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.54117647 0.99607843 0.99607843\n",
      "  0.45490196 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.0745098  0.69411765 0.35294118 0.         0.         0.\n",
      "  0.         0.         0.09803922 0.94117647 0.99607843 0.99607843\n",
      "  0.13333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.64313725 0.99607843 0.84313725 0.24705882 0.14117647 0.\n",
      "  0.2        0.34901961 0.80784314 0.99607843 0.99607843 0.54509804\n",
      "  0.03137255 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.22352941 0.77254902 0.99607843 0.99607843 0.87058824 0.70588235\n",
      "  0.94509804 0.99607843 0.99607843 0.99215686 0.83529412 0.04313725\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.54901961 0.41176471 0.99607843 0.99607843 0.99607843\n",
      "  0.99607843 0.99607843 0.99607843 0.9254902  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.02745098 0.45882353 0.45882353 0.64705882\n",
      "  0.99607843 0.99607843 0.9372549  0.19607843 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the normalized pixel values of a specific image (in this case, the 10th image)\n",
    "print('Normalized Pixel Values of the 10th Image:', x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f34f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Flatten the input data (convert 28x28 images to a 1D array of 784 elements)\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Add a densely connected layer with 128 units and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add another densely connected layer with 32 units and ReLU activation\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer with 10 units (for 10 classes) and softmax activation\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e6300d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104938 (409.91 KB)\n",
      "Trainable params: 104938 (409.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b09d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network\n",
    "model.compile(\n",
    "    optimizer='adam',                  # Specify the optimization algorithm (Adam optimizer is commonly used)\n",
    "    loss='sparse_categorical_crossentropy',  # Specify the loss function (used for training, suitable for classification)\n",
    "    metrics=['accuracy']               # Specify evaluation metrics (accuracy will be calculated during training)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b42ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.2874 - accuracy: 0.9165 - val_loss: 0.1704 - val_accuracy: 0.9499\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1213 - accuracy: 0.9632 - val_loss: 0.1189 - val_accuracy: 0.9638\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 0.1001 - val_accuracy: 0.9707\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0621 - accuracy: 0.9810 - val_loss: 0.0985 - val_accuracy: 0.9722\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.1060 - val_accuracy: 0.9702\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.1026 - val_accuracy: 0.9732\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.1083 - val_accuracy: 0.9719\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.1080 - val_accuracy: 0.9748\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.1022 - val_accuracy: 0.9764\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.1185 - val_accuracy: 0.9731\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.1117 - val_accuracy: 0.9759\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.1233 - val_accuracy: 0.9746\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1500 - val_accuracy: 0.9674\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.1227 - val_accuracy: 0.9749\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.1571 - val_accuracy: 0.9698\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.1279 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1487 - val_accuracy: 0.9732\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.1454 - val_accuracy: 0.9732\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1545 - val_accuracy: 0.9731\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1357 - val_accuracy: 0.9772\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1688 - val_accuracy: 0.9736\n",
      "Epoch 22/25\n",
      " 261/1500 [====>.........................] - ETA: 3s - loss: 0.0116 - accuracy: 0.9959"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data (x_train and y_train) for 25 epochs with a 20% validation split\n",
    "history = model.fit(x_train,y_train,epochs=25,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Keras model to a file named 'keras_model.h5'\n",
    "#model.save('keras_model.h52')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e5194",
   "metadata": {},
   "source": [
    "Training data Accuracy = 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcef3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the accuracy of the model on the test data\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac349773",
   "metadata": {},
   "source": [
    "Test data Accuracy = 97.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68258af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'])         # Plot the training loss for each epoch\n",
    "plt.plot(history.history['val_loss'])     # Plot the validation loss for each epoch\n",
    "plt.xlabel('Epoch')                       # Label the x-axis as 'Epoch'\n",
    "plt.ylabel('Loss')                        # Label the y-axis as 'Loss'\n",
    "plt.legend(['Training Loss', 'Validation Loss'])  # Add a legend to the plot to distinguish between training and validation loss\n",
    "plt.show()                                # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ef25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')  # Plot the training accuracy for each epoch\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')  # Plot the validation accuracy for each epoch\n",
    "plt.xlabel('Epoch')  # Label the x-axis as 'Epoch'\n",
    "plt.ylabel('Accuracy')  # Label the y-axis as 'Accuracy'\n",
    "plt.legend()  # Add a legend to the plot to distinguish between training and validation accuracy\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62df8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the test data (x_test)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first image in the test data\n",
    "plt.imshow(x_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea74764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the true label of the first image in the test data\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da96a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98726d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted probabilities for the first image\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1df80",
   "metadata": {},
   "source": [
    "Model.predict() gives the prediction probability of each class for that data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prediction probability to a class label for the first image\n",
    "label_for_first_time_image = np.argmax(y_pred[0])\n",
    "print(label_for_first_time_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f41094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted probabilities for all test images to class labels\n",
    "y_pred_labels = [np.argmax(i) for i in y_pred]\n",
    "\n",
    "# Print the class labels for all test images\n",
    "print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed843d",
   "metadata": {},
   "source": [
    "Y_test --> True Labels  ,  Y_pred_labels --> Predicted Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab3b17",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a03530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix to evaluate model performance\n",
    "conf_mat = confusion_matrix(y_test, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670613cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(15, 7))  # Set the figure size to 15 inches in width and 7 inches in height\n",
    "\n",
    "# Generate a heatmap of the confusion matrix with annotations, using a blue color map ('Blues')\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.ylabel('True Labels')  # Label the y-axis as 'True Labels'\n",
    "plt.xlabel('Predicted Labels')  # Label the x-axis as 'Predicted Labels'\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c73e2",
   "metadata": {},
   "source": [
    "# Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d661723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ask the user for the path of the image to be predicted\n",
    "input_image_path = input('Path of the image to be predicted: ')\n",
    "\n",
    "# Load the input image using OpenCV\n",
    "input_image = cv2.imread(input_image_path)\n",
    "\n",
    "# Use matplotlib to display the input image\n",
    "plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))  # Display the image in RGB format\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n",
    "\n",
    "# Convert the input image to grayscale\n",
    "grayscale = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Resize the grayscale image to the same dimensions as the model input (28x28 pixels)\n",
    "input_image_resize = cv2.resize(grayscale, (28, 28))\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "input_image_resize = input_image_resize / 255\n",
    "\n",
    "# Reshape the image to match the model's input shape (1, 28, 28)\n",
    "image_reshaped = np.reshape(input_image_resize, [1, 28, 28])\n",
    "\n",
    "# Use the trained model to make a prediction on the input image\n",
    "input_prediction = model.predict(image_reshaped)\n",
    "\n",
    "# Find the predicted label (the digit recognized from the input image)\n",
    "input_pred_label = np.argmax(input_prediction)\n",
    "\n",
    "# Print the recognized digit label\n",
    "print('The Handwritten Digit is recognized as :-', input_pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae148ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
